tidy_books %>%
filter(book = "Emma") %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n),
n,
fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n),
n,
fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
library(tidyverse)
library(tidytext)
library(ggplot2)
library(gutenbergr)
library(janeaustenr)
# Input the poem into the `text` variable
text <- c("If you can dream – and not make dreams your master;",
"If you can think – and not make thoughts your aim;",
"If you can meet with Triumph and Disaster",
"And treat those two impostors just the same;",
"If you can bear to hear the truth you’ve spoken",
"Twisted by knaves to make a trap for fools,",
"Or watch the things you gave your life to, broken,",
"And stoop and build ’em up with worn-out tools:")
text
# Put text in a data frame, one line per row
text_df <- data_frame(line = 1:8, text = text)
text_df
# what we want is one word per row. unnest_tokens breaks out words
text_df %>%
unnest_tokens(word, text)
tidy_book %>%
count(word, sort = TRUE) %>%
top_n(20) %>%
ggplot(aes(fct_reorder(word, n), n)) +
geom_col() +
coord_flip()
full_text <- gutenberg_download(135)
tidy_book <- full_text %>%
mutate(line = row_number()) %>%
unnest_tokens(word, text)
tidy_book
tidy_book %>%
count(word, sort = TRUE) %>%
top_n(20) %>%
ggplot(aes(fct_reorder(word, n), n)) +
geom_col() +
coord_flip()
get_stopwords()
view(stop_words)
get_sentiments("afinn")
get_sentiments("bing")
get_sentiments("nrc")
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
tidy_books
total_words <- tidy_books %>%
group_by(book) %>%
count(book, word, sort = TRUE) %>%
summarize(total = sum(n)) %>%
ungroup()
book_words <- tidy_books %>%
anti_join(stop_words) %>%
count(book, word, sort = TRUE)
total_words <- book_words %>%
group_by(book) %>%
summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
ggplot(book_words, words, aes(n/total, fill = book)) +
geom_histogram(show.legend = FALSE) +
xlim(NA, 0.0009) +
facet_wrap(~book, ncol = 2, scales = "free_y")
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE)
tidy_books %>%
filter(book == "Emma") %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n), n, fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
cutoms_stop_words <- bind_rows(tibble(word = c("miss"), lexicon = c("custom")), stop_words)
cutoms_stop_words
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
tidy_books %>%
filter(book == "Emma") %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n), n, fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(get_sentiments("bing")) %>%
anti_join(custom_stop_words) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n), n, fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
cutoms_stop_words <- bind_rows(tibble(word = c("miss"), lexicon = c("custom")), stop_words)
tidy_books %>%
filter(book == "Emma") %>%
inner_join(get_sentiments("bing")) %>%
anti_join(custom_stop_words) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n), n, fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
custom_stop_words <- bind_rows(tibble(word = c("miss"), lexicon = c("custom")), stop_words)
tidy_books %>%
filter(book == "Emma") %>%
inner_join(get_sentiments("bing")) %>%
anti_join(custom_stop_words) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n), n, fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
custom_stop_words <- tibble(word = c("miss"), lexicon = c("custom"))
tidy_books %>%
filter(book == "Emma") %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n), n, fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(get_sentiments("bing")) %>%
anti_join(custom_stop_words) %>%
count(sentiment, word, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, n), n, fill = sentiment)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free")
jane_austen_sentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
full_collection <- gutenberg_download(c(1342, 158, 161, 141),
meta_fields = "title")
# count the number of words per book
full_collection %>% count(title)
book_words <- full_collection %>%
unnest_tokens(word, text) %>%
count(title, word, sort = TRUE)
book_words
charlesdickens_collection <- gutenberg_download(c(1400, 158, 161, 141),
meta_fields = "title")
charlesdickens_collection
charlesdickens_collection <- gutenberg_download(c(1400, 98, 1023, 24022, 766, 730),
meta_fields = "title")
tidy_dickens <- charlesdickens_collection %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
charlesdickens_collection
charlesdickens_collection <- gutenberg_download(c(1400, 98, 1023, 24022, 766, 730))
charlesdickens_collection
charlesdickens_collection %>% count(title)
charlesdickens_collection <- gutenberg_download(c(1400, 98, 1023, 24022, 766, 730),
meta_fields = "title")
charlesdickens_collection %>% count(title)
tidy_collection <- charlesdickens_collection %>%
unnest_tokens(word, text) %>%
count(title, word, sort = TRUE)
tidy_collection
tidy_collection <- charlesdickens_collection %>%
unnest_tokens(word, text)
tidy_collection
tidy_collection <- charlesdickens_collection %>%
unnest_tokens(word, text) %>%
count(title, word, sort = TRUE)
tidy_collection
charles_dickens_sentiment <- tidy_collection %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
charlesdickens_collection <- gutenberg_download(c(1400, 98, 1023, 24022, 766, 730),
meta_fields = "title")
charlesdickens_collection %>% count(title)
charlesdickens_collection
tidy_dickens <- charlesdickens_collection %>%
group_by(title) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
tidy_dickens
charle_sdickens_collection <- gutenberg_download(c(1400, 98, 1023, 24022, 766, 730),
meta_fields = "title")
charles_dickens_collection %>% count(title)
# Tidy the corpus
tidy_dickens <- charles_dickens_collection %>%
group_by(title) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
charles_dickens_collection <- gutenberg_download(c(1400, 98, 1023, 24022, 766, 730),
meta_fields = "title")
charles_dickens_collection %>% count(title)
# Tidy the corpus
tidy_dickens <- charles_dickens_collection %>%
group_by(title) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
charles_dickens_sentiment <- tidy_dickens %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(charles_dickens_sentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
charles_dickens_sentiment <- tidy_dickens %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
charles_dickens_sentiment <- tidy_dickens %>%
inner_join(get_sentiments("bing")) %>%
count(title, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
charles_dickens_sentiment
ggplot(charles_dickens_sentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
ggplot(charles_dickens_sentiment, aes(index, sentiment, fill = title)) +
geom_col(show.legend = FALSE) +
facet_wrap(~title, ncol = 2, scales = "free_x")
pride_prejudice <- tidy_books %>%
filter(book == "Pride & Prejudice")
pride_prejudice
afinn <- pride_prejudice %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(score)) %>%
mutate(method = "AFINN")
bing_and_nrc <- bind_rows(pride_prejudice %>%
inner_join(get_sentiments("bing")) %>%
mutate(method = "Bing et al."), pride_prejudice %>%
inner_join(get_sentiments("nrc") %>%
filter(sentiment %in% c("positive", "negative"))) %>%
mutate(method = "NRC")) %>%
count(method, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
bind_rows(afinn, bing_and_nrc) %>%
ggplot(aes(index, sentiment, fill = method)) +
geom_col(show.legend = FALSE) +
facet_wrap(~method, ncol = 1, scales = "free_y")
tidy_dickens
two_cities <- tidy_dickens %>%
filter(book == "A Tale of Two Cities")
two_cities
two_cities <- tidy_dickens %>%
filter(title == "A Tale of Two Cities")
two_cities
afinn <- two_cities %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(score)) %>%
mutate(method = "AFINN")
bing_and_nrc <- bind_rows(two_cities %>%
inner_join(get_sentiments("bing")) %>%
mutate(method = "Bing et al."), two_cities %>%
inner_join(get_sentiments("nrc") %>%
filter(sentiment %in% c("positive", "negative"))) %>%
mutate(method = "NRC")) %>%
count(method, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
bind_rows(afinn, bing_and_nrc) %>%
ggplot(aes(index, sentiment, fill = method)) +
geom_col(show.legend = FALSE) +
facet_wrap(~method, ncol = 1, scales = "free_y")
bing_word_counts <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
bing_word_counts %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Contribution to Sentiment", x = NULL) +
coord_flip()
book_tfidf <- book_words %>%
bind_tf_idf(word, title, n)
book_tfidf
book_tfidf %>%
arrange(-tf_idf)
book_tfidf %>%
group_by(title) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, tf_idf),
tf_idf,
fill = title)) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~title, scales = "free")
full_collection <- gutenberg_download(c(1342, 158, 161, 141),
meta_fields = "title")
# count the number of words per book
full_collection %>% count(title)
# Count the word frequencies in your collection, by title.
book_words <- full_collection %>%
unnest_tokens(word, text) %>%
count(title, word, sort = TRUE)
book_words
## Calculate tf-idf: term frequency - inverse document frequency. the weight is a statstical measure
## used to evaluate how important a word is to a document in a collection. The importance increases
## proportionally to the number of times a word appears in a document but is offset by the frequency
## of the word in the collection (corpus).
## Calculate tf-idf.
book_tfidf <- book_words %>%
bind_tf_idf(word, title, n)
book_tfidf
# Find *high* tf-idf words.
book_tfidf %>%
arrange(-tf_idf)
# How can we visualize this? Let's go step-by-step.
book_tfidf %>%
group_by(title) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, tf_idf),
tf_idf,
fill = title)) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~title, scales = "free")
full_collection <- gutenberg_download(c(98, 4300, 844, 135),
meta_fields = "title")
# count the number of words per book
full_collection %>% count(title)
# Count the word frequencies in your collection, by title.
book_words <- full_collection %>%
unnest_tokens(word, text) %>%
count(title, word, sort = TRUE)
book_words
## Calculate tf-idf: term frequency - inverse document frequency. the weight is a statstical measure
## used to evaluate how important a word is to a document in a collection. The importance increases
## proportionally to the number of times a word appears in a document but is offset by the frequency
## of the word in the collection (corpus).
## Calculate tf-idf.
book_tfidf <- book_words %>%
bind_tf_idf(word, title, n)
book_tfidf
# Find *high* tf-idf words.
book_tfidf %>%
arrange(-tf_idf)
# How can we visualize this? Let's go step-by-step.
book_tfidf %>%
group_by(title) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, tf_idf),
tf_idf,
fill = title)) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~title, scales = "free")
tidy_dickens
book_words
tidy_dickens
book_words <- tidy_dickens %>%
unnest_tokens(word, text) %>%
count(title, word, sort = TRUE)
book_words
book_tfidf <- book_words %>%
bind_tf_idf(word, title, n)
book_tfidf
book_tfidf %>%
arrange(-tf_idf)
book_tfidf <- book_words %>%
bind_tf_idf(word, title, n) %>%
arrange(-tf_idf)
book_tfidf
book_tfidf %>%
group_by(title) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, tf_idf),
tf_idf,
fill = title)) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~title, scales = "free")
book_words <- tidy_dickens %>%
unnest_tokens(word, text) %>%
count(title, word, sort = TRUE)
book_words
## Calculate tf-idf: term frequency - inverse document frequency. the weight is a statstical measure
## used to evaluate how important a word is to a document in a collection. The importance increases
## proportionally to the number of times a word appears in a document but is offset by the frequency
## of the word in the collection (corpus).
## Calculate tf-idf and arrange by "high" tf-idf words.
book_tfidf <- book_words %>%
bind_tf_idf(word, title, n) %>%
arrange(-tf_idf)
book_tfidf
# visulaize tf-dif by book.
book_tfidf %>%
group_by(title) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, tf_idf),
tf_idf,
fill = title)) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~title, scales = "free")
tidy_dickens
unique(tidy_dickens)
tidy_dickens %>%
unique(title)
unique(tidy_dickens$title)
book_words <- tidy_dickens %>%
unnest_tokens(word, text) %>%
count(title, word, sort = TRUE)
tidy_dickens
book_words <- tidy_dickens %>%
count(title, word, sort = TRUE)
book_words
book_tfidf <- book_words %>%
bind_tf_idf(word, title, n) %>%
arrange(-tf_idf)
book_tfidf
book_tfidf %>%
group_by(title) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(fct_reorder(word, tf_idf),
tf_idf,
fill = title)) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~title, scales = "free")
View(jane_austen_sentiment)
getwd()
